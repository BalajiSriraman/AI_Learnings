{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/balaji/.pyenv/versions/3.10.16/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting tensorflow-macos\n",
      "  Downloading tensorflow_macos-2.16.2-cp310-cp310-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Collecting tensorflow-metal\n",
      "  Downloading tensorflow_metal-1.2.0-cp310-cp310-macosx_12_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow==2.16.2\n",
      "  Downloading tensorflow-2.16.2-cp310-cp310-macosx_12_0_arm64.whl (227.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.0/227.0 MB\u001b[0m \u001b[31m947.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:05\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/balaji/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/balaji/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.17.2)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: setuptools in /Users/balaji/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (65.5.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m752.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: packaging in /Users/balaji/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (24.2)\n",
      "Collecting h5py>=3.10.0\n",
      "  Using cached h5py-3.13.0-cp310-cp310-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.17,>=2.16\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.2.0-py3-none-any.whl (276 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.0/277.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting keras>=3.0.0\n",
      "  Using cached keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl (11.3 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl (3.5 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/balaji/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.17.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.14.1-cp310-cp310-macosx_11_0_arm64.whl (327 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/balaji/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.19.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wheel, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, MarkupSafe, markdown, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, tensorflow-metal, requests, markdown-it-py, astunparse, tensorboard, rich, keras, tensorflow, tensorflow-macos\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.2.0 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-3.9.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 protobuf-4.25.6 requests-2.32.3 rich-13.9.4 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-macos-2.16.2 tensorflow-metal-1.2.0 termcolor-2.5.0 urllib3-2.3.0 werkzeug-3.1.3 wheel-0.45.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy tensorflow-macos tensorflow-metal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/balaji/.pyenv/versions/3.10.16/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-03-23 17:30:00.965084: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-03-23 17:30:00.965141: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-03-23 17:30:00.965152: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-03-23 17:30:00.965206: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-23 17:30:00.965223: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 17:30:02.602234: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.5000 - loss: 0.6898\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6875\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6667 - loss: 0.6851\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6667 - loss: 0.6827\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6667 - loss: 0.6802\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6667 - loss: 0.6777\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6667 - loss: 0.6752\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6667 - loss: 0.6725\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6667 - loss: 0.6698\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6667 - loss: 0.6671\n",
      "Embeddings and metadata saved to 'vecs.tsv' and 'meta.tsv'.\n",
      "To visualize embeddings, upload 'vecs.tsv' and 'meta.tsv' to the TensorFlow Embedding Projector:\n",
      "https://projector.tensorflow.org/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "import io\n",
    "\n",
    "# Step 1: Sample dataset\n",
    "sentences = [\n",
    "    \"I love this movie\",\n",
    "    \"This is an amazing movie\",\n",
    "    \"I hate this movie\",\n",
    "    \"This is a terrible movie\",\n",
    "    \"Fantastic performance by the actors\",\n",
    "    \"The plot was boring and predictable\"\n",
    "]\n",
    "labels = [1, 1, 0, 0, 1, 0]  # 1 = positive, 0 = negative\n",
    "\n",
    "# Step 2: Tokenize sentences\n",
    "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Pad sequences to ensure equal length\n",
    "padded_sequences = pad_sequences(sequences, padding='post', maxlen=10)\n",
    "\n",
    "# Step 3: Define the model with an embedding layer\n",
    "vocab_size = len(word_index) + 1  # Include the OOV token\n",
    "embedding_dim = 16  # Size of the embedding vector\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=10),\n",
    "    Flatten(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Build the model to initialize the layers\n",
    "model.build(input_shape=(None, 10))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "model.fit(padded_sequences, np.array(labels), epochs=10)\n",
    "\n",
    "# Step 5: Retrieve and save the embeddings\n",
    "# Get the weights from the embedding layer\n",
    "embedding_layer = model.layers[0]\n",
    "embeddings = embedding_layer.get_weights()[0]\n",
    "\n",
    "# Save embeddings and metadata to files\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for word, idx in word_index.items():\n",
    "    if idx < vocab_size:  # Ensure index is within vocab size\n",
    "        vec = embeddings[idx]\n",
    "        out_m.write(word + \"\\n\")  # Save the word\n",
    "        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")  # Save the vector\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "print(\"Embeddings and metadata saved to 'vecs.tsv' and 'meta.tsv'.\")\n",
    "\n",
    "# Step 6: Visualize embeddings\n",
    "print(\"To visualize embeddings, upload 'vecs.tsv' and 'meta.tsv' to the TensorFlow Embedding Projector:\")\n",
    "print(\"https://projector.tensorflow.org/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to a .tsv file\n",
    "import io\n",
    "\n",
    "# Get the weights from the embedding layer\n",
    "embedding_layer = model.layers[0]\n",
    "embeddings = embedding_layer.get_weights()[0]\n",
    "\n",
    "# Save the embeddings\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for word, idx in word_index.items():\n",
    "    if idx < vocab_size:  # Ensure we're within the vocab size\n",
    "        vec = embeddings[idx]\n",
    "        out_m.write(word + \"\\n\")  # Save the word\n",
    "        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")  # Save the vector\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "print(\"Embeddings and metadata saved to 'vecs.tsv' and 'meta.tsv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
